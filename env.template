# NVIDIA Tech Blog Agent - Environment Variables Template
# 
# Copy this file to .env and fill in your values:
#   cp env.template .env
#
# Or set these as environment variables in your shell/system.

# =============================================================================
# GCP PROJECT CONFIGURATION
# =============================================================================

# Your Google Cloud Project ID (required for Vertex AI RAG)
GOOGLE_CLOUD_PROJECT=nvidia-blog-agent

# Alternative: GCP_PROJECT (used if GOOGLE_CLOUD_PROJECT is not set)
# GCP_PROJECT=nvidia-blog-agent

# Path to service account JSON key file (required for GCP authentication)
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account.json

# =============================================================================
# GEMINI / LLM CONFIGURATION
# =============================================================================

# Gemini model name (default: gemini-1.5-pro)
# Options: gemini-1.5-pro, gemini-1.5-flash, gemini-2.0-flash-exp, etc.
GEMINI_MODEL_NAME=gemini-1.5-pro

# Gemini model location/region (optional, depends on deployment)
# Common values: us-central1, us-east1, europe-west1
GEMINI_LOCATION=us-central1

# =============================================================================
# RAG BACKEND CONFIGURATION
# =============================================================================
# 
# Choose ONE of the following RAG backends:
#   1. Vertex AI RAG Engine (Recommended) - Set USE_VERTEX_RAG=true
#   2. HTTP-based RAG - Leave USE_VERTEX_RAG unset or false

# -----------------------------------------------------------------------------
# OPTION 1: Vertex AI RAG Engine (Recommended)
# -----------------------------------------------------------------------------

# Enable Vertex AI RAG Engine (set to "true" to use Vertex RAG)
USE_VERTEX_RAG=true

# Vertex AI RAG Corpus ID (numeric ID from your RAG corpus resource)
# Format: Just the numeric ID, e.g., "1234567890123456789"
# Get this from: Vertex AI RAG Engine Console > Your Corpus > Resource Name
RAG_CORPUS_ID=1234567890123456789

# Vertex AI region/location (must match your RAG corpus and Search data store)
# Common values: us-central1, us-east1, europe-west1
VERTEX_LOCATION=us-central1

# GCS bucket for storing RAG documents
# Format: gs://bucket-name (with or without trailing slash)
# This bucket should be configured as the data source for Vertex AI Search
RAG_DOCS_BUCKET=gs://nvidia-blog-rag-docs

# Optional: Vertex AI Search serving config resource name
# Format: projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/servingConfigs/{serving_config}
# Only needed if querying Search directly (not typically required)
# RAG_SEARCH_ENGINE_NAME=projects/nvidia-blog-agent/locations/us-central1/collections/default_collection/dataStores/nvidia-blog-docs/servingConfigs/default_search

# -----------------------------------------------------------------------------
# OPTION 2: HTTP-based RAG Backend (Alternative)
# -----------------------------------------------------------------------------
# 
# Uncomment and configure these if using HTTP RAG instead of Vertex RAG:
# (Make sure USE_VERTEX_RAG is NOT set to "true")

# RAG_BASE_URL=https://your-rag-service.run.app
# RAG_UUID=your-corpus-uuid
# RAG_API_KEY=your-optional-api-key

# =============================================================================
# STATE PERSISTENCE
# =============================================================================

# Path for state persistence (tracks previously seen blog post IDs, ingestion history)
# 
# Development: Use a local JSON file
STATE_PATH=state.json

# Production: Use a GCS bucket (recommended for production)
# STATE_PATH=gs://nvidia-blog-agent-state/state.json

# =============================================================================
# OPTIONAL: NVIDIA BLOG FEED CONFIGURATION
# =============================================================================

# Custom NVIDIA blog feed URL (optional, defaults to official NVIDIA Tech Blog feed)
# FEED_URL=https://developer.nvidia.com/blog/feed/

# =============================================================================
# MCP SERVER CONFIGURATION (Optional)
# =============================================================================
#
# These variables are only needed if running the MCP server (nvidia_blog_mcp_server.py)
#
# Cloud Run service URL (get from: gcloud run services describe nvidia-blog-agent --region us-central1 --format='value(status.url)')
# NVIDIA_BLOG_SERVICE_URL=https://nvidia-blog-agent-xxxxx-uc.a.run.app
#
# Ingest API key (same value stored in Secret Manager for Cloud Run)
# This allows the MCP server to call the protected /ingest endpoint
# INGEST_API_KEY=your-very-strong-random-key

# =============================================================================
# NOTES
# =============================================================================
#
# 1. For Vertex AI RAG setup, see VERTEX_RAG_SETUP.md for complete instructions
#
# 2. Required variables for Vertex AI RAG:
#    - GOOGLE_CLOUD_PROJECT
#    - GOOGLE_APPLICATION_CREDENTIALS
#    - USE_VERTEX_RAG=true
#    - RAG_CORPUS_ID
#    - VERTEX_LOCATION
#    - RAG_DOCS_BUCKET
#    - GEMINI_MODEL_NAME
#
# 3. Required variables for HTTP RAG:
#    - RAG_BASE_URL
#    - RAG_UUID
#    - GEMINI_MODEL_NAME
#
# 4. STATE_PATH is optional but recommended (defaults to state.json if not set)
#
# 5. All boolean values (like USE_VERTEX_RAG) should be lowercase "true" or "false"
#    (case-insensitive, but "true" is the standard)

